{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/anaconda3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.6 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.7\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "from sklearn.svm import SVC\n",
    "from keras.models import Sequential\n",
    "from keras.layers.recurrent import LSTM, GRU\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import np_utils\n",
    "from sklearn import preprocessing, decomposition, model_selection, metrics, pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from keras.layers import GlobalMaxPooling1D, Conv1D, MaxPooling1D, Flatten, Bidirectional, SpatialDropout1D\n",
    "from keras.preprocessing import sequence, text\n",
    "from keras.callbacks import EarlyStopping\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "from scipy import sparse\n",
    "from sklearn.metrics import log_loss,confusion_matrix,classification_report,roc_curve,auc, accuracy_score\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train : (159571,)\n",
      "test  : (153164,)\n",
      "train + test : (312735,)\n"
     ]
    }
   ],
   "source": [
    "dftrain = pd.read_csv('datasources/jigsaw1/train.csv').fillna(' ')\n",
    "dftest = pd.read_csv('datasources/jigsaw1/test.csv').fillna(' ')\n",
    "\n",
    "traincomments = dftrain['comment_text']\n",
    "testcomments = dftest['comment_text']\n",
    "wikicomments = pd.concat([traincomments, testcomments])\n",
    "\n",
    "wikicomments = wikicomments\n",
    "print('train : {}'.format(traincomments.shape))\n",
    "print('test  : {}'.format(testcomments.shape))\n",
    "print('train + test : {}'.format(wikicomments.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107657    ==Fuck You== \\n If you dont accept the faceboo...\n",
       "152463    \" \\n\\n ==Bobby Sands== \\n\\n Thanks. I apprecia...\n",
       "90615     Pewep, a zSilencer proprietor, continues to is...\n",
       "140845    == Ok == \\n\\n I was just testing to see how qu...\n",
       "43531     YOU People are stupid fuuuck am I annoying com...\n",
       "110906    Please stop adding nonsense to Wikipedia.  It ...\n",
       "121480    == project invite == \\n\\n Hi Shaun, I'm messag...\n",
       "108049                             I am awesome so suck it.\n",
       "32727     \" \\n\\n == GAY! == \\n\\n I LOVE TEH TOUCHING PEN...\n",
       "136380    :::Rick, you always have a way of putting thin...\n",
       "Name: comment_text, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftest['comment_text'].sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse par  tfidf: TfidfVectorizer =  CountVectorizer + TfidfTransformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect_word = TfidfVectorizer(max_features=20000, lowercase=True, analyzer='word',\n",
    "                        stop_words= 'english',ngram_range=(1,3),dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word ngram vector\n",
    "train_vect = vect_word.fit_transform(dftrain['comment_text'])\n",
    "test_vect = vect_word.transform(dftest['comment_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159571, 20000)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_vect.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000\n"
     ]
    }
   ],
   "source": [
    "print(len(vect_word.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect_char = TfidfVectorizer(max_features=40000, lowercase=True, analyzer='char',\n",
    "                        stop_words= 'english',ngram_range=(3,6),dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Character n gram vector\n",
    "tr_vect_char = vect_char.fit_transform(dftrain['comment_text'])\n",
    "ts_vect_char = vect_char.transform(dftest['comment_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n\"\"',\n",
       " '\\nan',\n",
       " '\\nbu',\n",
       " '\\nhe',\n",
       " '\\nhel',\n",
       " '\\nhi',\n",
       " '\\nho',\n",
       " '\\nhow',\n",
       " '\\nhow ',\n",
       " '\\nhow t',\n",
       " '\\nht',\n",
       " '\\nhtt',\n",
       " '\\nhttp',\n",
       " '\\nhttp:',\n",
       " '\\ni ',\n",
       " '\\ni a',\n",
       " '\\ni h',\n",
       " \"\\ni'\",\n",
       " '\\nif',\n",
       " '\\nif ',\n",
       " '\\nin',\n",
       " '\\nit',\n",
       " '\\nma',\n",
       " '\\nno',\n",
       " '\\npl',\n",
       " '\\nple',\n",
       " '\\nplea',\n",
       " '\\npleas',\n",
       " '\\nso',\n",
       " '\\nth',\n",
       " '\\ntha',\n",
       " '\\nthan',\n",
       " '\\nthank',\n",
       " '\\nthe',\n",
       " '\\nthe ',\n",
       " '\\nthe f',\n",
       " '\\nthi',\n",
       " '\\nthis',\n",
       " '\\nthis ',\n",
       " '\\nwe',\n",
       " '\\nwh',\n",
       " '\\nwi',\n",
       " '\\nyo',\n",
       " '\\nyou',\n",
       " '\\nyou ',\n",
       " '\\n|-',\n",
       " ' \"\"',\n",
       " ' \"\" ',\n",
       " ' \"\"a',\n",
       " ' \"\"an',\n",
       " ' \"\"b',\n",
       " ' \"\"c',\n",
       " ' \"\"co',\n",
       " ' \"\"con',\n",
       " ' \"\"d',\n",
       " ' \"\"de',\n",
       " ' \"\"di',\n",
       " ' \"\"e',\n",
       " ' \"\"f',\n",
       " ' \"\"g',\n",
       " ' \"\"h',\n",
       " ' \"\"i',\n",
       " ' \"\"in',\n",
       " ' \"\"j',\n",
       " ' \"\"l',\n",
       " ' \"\"m',\n",
       " ' \"\"ma',\n",
       " ' \"\"n',\n",
       " ' \"\"no',\n",
       " ' \"\"o',\n",
       " ' \"\"p',\n",
       " ' \"\"pr',\n",
       " ' \"\"r',\n",
       " ' \"\"re',\n",
       " ' \"\"s',\n",
       " ' \"\"se',\n",
       " ' \"\"so',\n",
       " ' \"\"t',\n",
       " ' \"\"th',\n",
       " ' \"\"the',\n",
       " ' \"\"u',\n",
       " ' \"\"un',\n",
       " ' \"\"v',\n",
       " ' \"\"w',\n",
       " ' \"\"wh',\n",
       " ' \"\"y',\n",
       " ' & ',\n",
       " \" ''\",\n",
       " \" '''\",\n",
       " \" ''''\",\n",
       " \" '''''\",\n",
       " \" 'c\",\n",
       " \" 'i\",\n",
       " \" 's\",\n",
       " ' ( ',\n",
       " ' (1',\n",
       " ' (19',\n",
       " ' (2',\n",
       " ' (a',\n",
       " ' (al',\n",
       " ' (an',\n",
       " ' (and',\n",
       " ' (and ',\n",
       " ' (as',\n",
       " ' (as ',\n",
       " ' (b',\n",
       " ' (c',\n",
       " ' (co',\n",
       " ' (d',\n",
       " ' (e',\n",
       " ' (f',\n",
       " ' (fo',\n",
       " ' (g',\n",
       " ' (h',\n",
       " ' (i',\n",
       " ' (i ',\n",
       " ' (in',\n",
       " ' (in ',\n",
       " ' (j',\n",
       " ' (l',\n",
       " ' (m',\n",
       " ' (n',\n",
       " ' (no',\n",
       " ' (not',\n",
       " ' (o',\n",
       " ' (or',\n",
       " ' (or ',\n",
       " ' (p',\n",
       " ' (r',\n",
       " ' (s',\n",
       " ' (se',\n",
       " ' (see',\n",
       " ' (see ',\n",
       " ' (t',\n",
       " ' (ta',\n",
       " ' (tal',\n",
       " ' (talk',\n",
       " ' (th',\n",
       " ' (the',\n",
       " ' (the ',\n",
       " ' (u',\n",
       " ' (ut',\n",
       " ' (utc',\n",
       " ' (utc)',\n",
       " ' (w',\n",
       " ' (wh',\n",
       " ' (whi',\n",
       " ' (whic',\n",
       " ' (y',\n",
       " ' (yo',\n",
       " ' (~',\n",
       " ' (~~',\n",
       " ' (~~~',\n",
       " ' (~~~~',\n",
       " ' ) ',\n",
       " ' , ',\n",
       " ' , a',\n",
       " ' - ',\n",
       " ' - \"',\n",
       " ' - a',\n",
       " ' - an',\n",
       " ' - b',\n",
       " ' - i',\n",
       " ' - i ',\n",
       " ' - s',\n",
       " ' - t',\n",
       " ' - th',\n",
       " ' - the',\n",
       " ' - w',\n",
       " ' . ',\n",
       " ' . i',\n",
       " ' ..',\n",
       " ' ...',\n",
       " ' ... ',\n",
       " ' / ',\n",
       " ' 1 ',\n",
       " ' 1.',\n",
       " ' 10',\n",
       " ' 10 ',\n",
       " ' 100',\n",
       " ' 11',\n",
       " ' 12',\n",
       " ' 13',\n",
       " ' 14',\n",
       " ' 15',\n",
       " ' 16',\n",
       " ' 17',\n",
       " ' 18',\n",
       " ' 19',\n",
       " ' 194',\n",
       " ' 196',\n",
       " ' 197',\n",
       " ' 198',\n",
       " ' 199',\n",
       " ' 2 ',\n",
       " ' 2.',\n",
       " ' 20',\n",
       " ' 20 ',\n",
       " ' 200',\n",
       " ' 2004',\n",
       " ' 2004 ',\n",
       " ' 2005',\n",
       " ' 2005 ',\n",
       " ' 2006',\n",
       " ' 2006 ',\n",
       " ' 2007',\n",
       " ' 2007 ',\n",
       " ' 2008',\n",
       " ' 2008 ',\n",
       " ' 2009',\n",
       " ' 2009 ',\n",
       " ' 201',\n",
       " ' 2010',\n",
       " ' 2011',\n",
       " ' 2012',\n",
       " ' 21',\n",
       " ' 22',\n",
       " ' 23',\n",
       " ' 24',\n",
       " ' 24 ',\n",
       " ' 25',\n",
       " ' 3 ',\n",
       " ' 30',\n",
       " ' 3r',\n",
       " ' 4 ',\n",
       " ' 5 ',\n",
       " ' 50',\n",
       " ' 6 ',\n",
       " ' 7 ',\n",
       " ' = ',\n",
       " ' ==',\n",
       " ' == ',\n",
       " ' ===',\n",
       " ' ? ',\n",
       " ' [[',\n",
       " ' a ',\n",
       " ' a \"',\n",
       " ' a \"\"',\n",
       " ' a b',\n",
       " ' a ba',\n",
       " ' a bad',\n",
       " ' a be',\n",
       " ' a bet',\n",
       " ' a bi',\n",
       " ' a big',\n",
       " ' a bit',\n",
       " ' a bl',\n",
       " ' a blo',\n",
       " ' a bo',\n",
       " ' a br',\n",
       " ' a bu',\n",
       " ' a c',\n",
       " ' a ca',\n",
       " ' a ch',\n",
       " ' a cha',\n",
       " ' a ci',\n",
       " ' a cl',\n",
       " ' a co',\n",
       " ' a com',\n",
       " ' a con',\n",
       " ' a cop',\n",
       " ' a cou',\n",
       " ' a cr',\n",
       " ' a cu',\n",
       " ' a d',\n",
       " ' a da',\n",
       " ' a de',\n",
       " ' a di',\n",
       " ' a dic',\n",
       " ' a dif',\n",
       " ' a dis',\n",
       " ' a do',\n",
       " ' a f',\n",
       " ' a fa',\n",
       " ' a fai',\n",
       " ' a fe',\n",
       " ' a few',\n",
       " ' a fi',\n",
       " ' a fo',\n",
       " ' a for',\n",
       " ' a fr',\n",
       " ' a fre',\n",
       " ' a fu',\n",
       " ' a fuc',\n",
       " ' a g',\n",
       " ' a ge',\n",
       " ' a gen',\n",
       " ' a go',\n",
       " ' a goo',\n",
       " ' a gr',\n",
       " ' a gre',\n",
       " ' a h',\n",
       " ' a ha',\n",
       " ' a hi',\n",
       " ' a ho',\n",
       " ' a hu',\n",
       " ' a j',\n",
       " ' a jo',\n",
       " ' a k',\n",
       " ' a l',\n",
       " ' a la',\n",
       " ' a le',\n",
       " ' a li',\n",
       " ' a lin',\n",
       " ' a lis',\n",
       " ' a lit',\n",
       " ' a lo',\n",
       " ' a lon',\n",
       " ' a loo',\n",
       " ' a lot',\n",
       " ' a m',\n",
       " ' a ma',\n",
       " ' a me',\n",
       " ' a mes',\n",
       " ' a mi',\n",
       " ' a mis',\n",
       " ' a mo',\n",
       " ' a mor',\n",
       " ' a mu',\n",
       " ' a n',\n",
       " ' a na',\n",
       " ' a ne',\n",
       " ' a new',\n",
       " ' a ni',\n",
       " ' a no',\n",
       " ' a not',\n",
       " ' a nu',\n",
       " ' a num',\n",
       " ' a p',\n",
       " ' a pa',\n",
       " ' a pag',\n",
       " ' a par',\n",
       " ' a pe',\n",
       " ' a per',\n",
       " ' a pi',\n",
       " ' a pl',\n",
       " ' a pla',\n",
       " ' a po',\n",
       " ' a pr',\n",
       " ' a pre',\n",
       " ' a pro',\n",
       " ' a q',\n",
       " ' a qu',\n",
       " ' a que',\n",
       " ' a r',\n",
       " ' a ra',\n",
       " ' a re',\n",
       " ' a rea',\n",
       " ' a ref',\n",
       " ' a rel',\n",
       " ' a rep',\n",
       " ' a res',\n",
       " ' a s',\n",
       " ' a sc',\n",
       " ' a se',\n",
       " ' a sec',\n",
       " ' a sh',\n",
       " ' a si',\n",
       " ' a sim',\n",
       " ' a sin',\n",
       " ' a sm',\n",
       " ' a so',\n",
       " ' a soc',\n",
       " ' a sou',\n",
       " ' a sp',\n",
       " ' a spe',\n",
       " ' a st',\n",
       " ' a sta',\n",
       " ' a str',\n",
       " ' a su',\n",
       " ' a sub',\n",
       " ' a t',\n",
       " ' a ta',\n",
       " ' a te',\n",
       " ' a th',\n",
       " ' a to',\n",
       " ' a tr',\n",
       " ' a u',\n",
       " ' a us',\n",
       " ' a use',\n",
       " ' a v',\n",
       " ' a va',\n",
       " ' a ve',\n",
       " ' a ver',\n",
       " ' a vi',\n",
       " ' a w',\n",
       " ' a wa',\n",
       " ' a we',\n",
       " ' a wh',\n",
       " ' a whi',\n",
       " ' a wi',\n",
       " ' a wik',\n",
       " ' a wo',\n",
       " ' a wor',\n",
       " ' ab',\n",
       " ' abi',\n",
       " ' abl',\n",
       " ' able',\n",
       " ' able ',\n",
       " ' abo',\n",
       " ' abou',\n",
       " ' about',\n",
       " ' abov',\n",
       " ' above',\n",
       " ' abs',\n",
       " ' abso',\n",
       " ' absol',\n",
       " ' abu',\n",
       " ' abus',\n",
       " ' abuse',\n",
       " ' abusi',\n",
       " ' ac',\n",
       " ' aca',\n",
       " ' acad',\n",
       " ' acade',\n",
       " ' acc',\n",
       " ' acce',\n",
       " ' accep',\n",
       " ' acces',\n",
       " ' acco',\n",
       " ' accor',\n",
       " ' accou',\n",
       " ' accu',\n",
       " ' accur',\n",
       " ' accus',\n",
       " ' ach',\n",
       " ' achi',\n",
       " ' ack',\n",
       " ' acr',\n",
       " ' acro',\n",
       " ' acros',\n",
       " ' act',\n",
       " ' act ',\n",
       " ' acti',\n",
       " ' actio',\n",
       " ' activ',\n",
       " ' actu',\n",
       " ' actua',\n",
       " ' ad',\n",
       " ' add',\n",
       " ' add ',\n",
       " ' add a',\n",
       " ' add i',\n",
       " ' add t',\n",
       " ' adde',\n",
       " ' added',\n",
       " ' addi',\n",
       " ' addin',\n",
       " ' addit',\n",
       " ' addr',\n",
       " ' addre',\n",
       " ' adm',\n",
       " ' admi',\n",
       " ' admin',\n",
       " ' admit',\n",
       " ' ado',\n",
       " ' adv',\n",
       " ' adva',\n",
       " ' advan',\n",
       " ' adve',\n",
       " ' adver',\n",
       " ' advi',\n",
       " ' advic',\n",
       " ' advis',\n",
       " ' af',\n",
       " ' afd',\n",
       " ' afd ',\n",
       " ' aff',\n",
       " ' afr',\n",
       " ' afri',\n",
       " ' afric',\n",
       " ' aft',\n",
       " ' afte',\n",
       " ' after',\n",
       " ' ag',\n",
       " ' aga',\n",
       " ' agai',\n",
       " ' again',\n",
       " ' age',\n",
       " ' agen',\n",
       " ' agend',\n",
       " ' ago',\n",
       " ' ago ',\n",
       " ' agr',\n",
       " ' agre',\n",
       " ' agree',\n",
       " ' ah',\n",
       " ' ahe',\n",
       " ' ahea',\n",
       " ' ahead',\n",
       " ' ai',\n",
       " ' aid',\n",
       " ' aids',\n",
       " ' aids ',\n",
       " ' air',\n",
       " ' al',\n",
       " ' alb',\n",
       " ' albu',\n",
       " ' album',\n",
       " ' ale',\n",
       " ' ali',\n",
       " ' all',\n",
       " ' all ',\n",
       " ' all a',\n",
       " ' all c',\n",
       " ' all i',\n",
       " ' all m',\n",
       " ' all o',\n",
       " ' all p',\n",
       " ' all s',\n",
       " ' all t',\n",
       " ' all w',\n",
       " ' all y',\n",
       " ' all,',\n",
       " ' all, ',\n",
       " ' all.',\n",
       " ' all. ',\n",
       " ' alle',\n",
       " ' alleg',\n",
       " ' allo',\n",
       " ' allow',\n",
       " ' alm',\n",
       " ' almo',\n",
       " ' almos',\n",
       " ' alo',\n",
       " ' alon',\n",
       " ' alone',\n",
       " ' along',\n",
       " ' alr',\n",
       " ' alre',\n",
       " ' alrea',\n",
       " ' als',\n",
       " ' also',\n",
       " ' also ',\n",
       " ' also,',\n",
       " ' alt',\n",
       " ' alte',\n",
       " ' alter',\n",
       " ' alth',\n",
       " ' altho',\n",
       " ' alw',\n",
       " ' alwa',\n",
       " ' alway',\n",
       " ' am',\n",
       " ' am ',\n",
       " ' am a',\n",
       " ' am a ',\n",
       " ' am g',\n",
       " ' am i',\n",
       " ' am n',\n",
       " ' am no',\n",
       " ' am s',\n",
       " ' am t',\n",
       " ' ama',\n",
       " ' ame',\n",
       " ' amer',\n",
       " ' ameri',\n",
       " ' amo',\n",
       " ' amon',\n",
       " ' among',\n",
       " ' amou',\n",
       " ' amoun',\n",
       " ' an',\n",
       " ' an ',\n",
       " ' an a',\n",
       " ' an ac',\n",
       " ' an ad',\n",
       " ' an an',\n",
       " ' an ap',\n",
       " ' an ar',\n",
       " ' an as',\n",
       " ' an at',\n",
       " ' an e',\n",
       " ' an ed',\n",
       " ' an en',\n",
       " ' an ex',\n",
       " ' an i',\n",
       " ' an im',\n",
       " ' an in',\n",
       " ' an o',\n",
       " ' an op',\n",
       " ' an u',\n",
       " ' an un',\n",
       " ' ana',\n",
       " ' anal',\n",
       " ' analy',\n",
       " ' anc',\n",
       " ' and',\n",
       " ' and ',\n",
       " ' and \"',\n",
       " ' and a',\n",
       " ' and b',\n",
       " ' and c',\n",
       " ' and d',\n",
       " ' and e',\n",
       " ' and f',\n",
       " ' and g',\n",
       " ' and h',\n",
       " ' and i',\n",
       " ' and j',\n",
       " ' and k',\n",
       " ' and l',\n",
       " ' and m',\n",
       " ' and n',\n",
       " ' and o',\n",
       " ' and p',\n",
       " ' and r',\n",
       " ' and s',\n",
       " ' and t',\n",
       " ' and u',\n",
       " ' and v',\n",
       " ' and w',\n",
       " ' and y',\n",
       " ' and,',\n",
       " ' and, ',\n",
       " ' ang',\n",
       " ' ani',\n",
       " ' anim',\n",
       " ' anima',\n",
       " ' ann',\n",
       " ' anno',\n",
       " ' ano',\n",
       " ' anon',\n",
       " ' anony',\n",
       " ' anot',\n",
       " ' anoth',\n",
       " ' ans',\n",
       " ' answ',\n",
       " ' answe',\n",
       " ' ant',\n",
       " ' anti',\n",
       " ' anti-',\n",
       " ' any',\n",
       " ' any ',\n",
       " ' any a',\n",
       " ' any c',\n",
       " ' any e',\n",
       " ' any f',\n",
       " ' any i',\n",
       " ' any m',\n",
       " ' any o',\n",
       " ' any p',\n",
       " ' any q',\n",
       " ' any r',\n",
       " ' any s',\n",
       " ' any t',\n",
       " ' any w',\n",
       " ' anym',\n",
       " ' anymo',\n",
       " ' anyo',\n",
       " ' anyon',\n",
       " ' anyt',\n",
       " ' anyth',\n",
       " ' anyw',\n",
       " ' anywa',\n",
       " ' ap',\n",
       " ' apo',\n",
       " ' apol',\n",
       " ' apolo',\n",
       " ' app',\n",
       " ' appa',\n",
       " ' appar',\n",
       " ' appe',\n",
       " ' appea',\n",
       " ' appl',\n",
       " ' appli',\n",
       " ' apply',\n",
       " ' appr',\n",
       " ' appre',\n",
       " ' appro',\n",
       " ' apr',\n",
       " ' apri',\n",
       " ' april',\n",
       " ' ar',\n",
       " ' ara',\n",
       " ' arab',\n",
       " ' arb',\n",
       " ' arbi',\n",
       " ' arbit',\n",
       " ' arc',\n",
       " ' arch',\n",
       " ' archi',\n",
       " ' are',\n",
       " ' are ',\n",
       " ' are a',\n",
       " ' are b',\n",
       " ' are c',\n",
       " ' are d',\n",
       " ' are e',\n",
       " ' are f',\n",
       " ' are g',\n",
       " ' are h',\n",
       " ' are i',\n",
       " ' are l',\n",
       " ' are m',\n",
       " ' are n',\n",
       " ' are o',\n",
       " ' are p',\n",
       " ' are r',\n",
       " ' are s',\n",
       " ' are t',\n",
       " ' are u',\n",
       " ' are v',\n",
       " ' are w',\n",
       " ' are y',\n",
       " ' area',\n",
       " ' area ',\n",
       " ' aren',\n",
       " \" aren'\",\n",
       " ' arg',\n",
       " ' argu',\n",
       " ' argue',\n",
       " ' argum',\n",
       " ' arm',\n",
       " ' arme',\n",
       " ' army',\n",
       " ' aro',\n",
       " ' arou',\n",
       " ' aroun',\n",
       " ' arr',\n",
       " ' art',\n",
       " ' arti',\n",
       " ' artic',\n",
       " ' artis',\n",
       " ' as',\n",
       " ' as ',\n",
       " ' as \"',\n",
       " ' as \"\"',\n",
       " ' as a',\n",
       " ' as a ',\n",
       " ' as an',\n",
       " ' as b',\n",
       " ' as be',\n",
       " ' as c',\n",
       " ' as d',\n",
       " ' as de',\n",
       " ' as e',\n",
       " ' as f',\n",
       " ' as fa',\n",
       " ' as fo',\n",
       " ' as h',\n",
       " ' as i',\n",
       " ' as i ',\n",
       " ' as in',\n",
       " ' as it',\n",
       " ' as l',\n",
       " ' as lo',\n",
       " ' as m',\n",
       " ' as mu',\n",
       " ' as n',\n",
       " ' as no',\n",
       " ' as o',\n",
       " ' as p',\n",
       " ' as po',\n",
       " ' as r',\n",
       " ' as re',\n",
       " ' as s',\n",
       " ' as so',\n",
       " ' as su',\n",
       " ' as t',\n",
       " ' as th',\n",
       " ' as to',\n",
       " ' as w',\n",
       " ' as we',\n",
       " ' as y',\n",
       " ' as yo',\n",
       " ' asi',\n",
       " ' asia',\n",
       " ' ask',\n",
       " ' ask ',\n",
       " ' ask m',\n",
       " ' ask t',\n",
       " ' ask y',\n",
       " ' aske',\n",
       " ' asked',\n",
       " ' aski',\n",
       " ' askin',\n",
       " ' asp',\n",
       " ' aspe',\n",
       " ' aspec',\n",
       " ' ass',\n",
       " ' ass ',\n",
       " ' ass.',\n",
       " ' ass. ',\n",
       " ' asse',\n",
       " ' asser',\n",
       " ' assh',\n",
       " ' assho',\n",
       " ' assi',\n",
       " ' assis',\n",
       " ' asso',\n",
       " ' assoc',\n",
       " ' assu',\n",
       " ' assum',\n",
       " ' at',\n",
       " ' at ',\n",
       " ' at a',\n",
       " ' at a ',\n",
       " ' at al',\n",
       " ' at an',\n",
       " ' at h',\n",
       " ' at i',\n",
       " ' at l',\n",
       " ' at le',\n",
       " ' at m',\n",
       " ' at s',\n",
       " ' at t',\n",
       " ' at th',\n",
       " ' at w',\n",
       " ' at wi',\n",
       " ' ath',\n",
       " ' att',\n",
       " ' atta',\n",
       " ' attac',\n",
       " ' atte',\n",
       " ' attem',\n",
       " ' atten',\n",
       " ' attr',\n",
       " ' attri',\n",
       " ' au',\n",
       " ' aug',\n",
       " ' augu',\n",
       " ' augus',\n",
       " ' aus',\n",
       " ' aust',\n",
       " ' austr',\n",
       " ' aut',\n",
       " ' auth',\n",
       " ' autho',\n",
       " ' auto',\n",
       " ' autom',\n",
       " ' av',\n",
       " ' ava',\n",
       " ' avai',\n",
       " ' avail',\n",
       " ' ave',\n",
       " ' avo',\n",
       " ' avoi',\n",
       " ' avoid',\n",
       " ' aw',\n",
       " ' awa',\n",
       " ' awar',\n",
       " ' award',\n",
       " ' aware',\n",
       " ' away',\n",
       " ' away ',\n",
       " ' ba',\n",
       " ' bab',\n",
       " ' bac',\n",
       " ' back',\n",
       " ' back ',\n",
       " ' backg',\n",
       " ' bad',\n",
       " ' bad ',\n",
       " ' bal',\n",
       " ' bala',\n",
       " ' balan',\n",
       " ' ball',\n",
       " ' balls',\n",
       " ' ban',\n",
       " ' ban ',\n",
       " ' band',\n",
       " ' band ',\n",
       " ' bann',\n",
       " ' banne',\n",
       " ' bar',\n",
       " ' bark',\n",
       " ' bark ',\n",
       " ' barn',\n",
       " ' barns',\n",
       " ' bas',\n",
       " ' base',\n",
       " ' based',\n",
       " ' basi',\n",
       " ' basic',\n",
       " ' basis',\n",
       " ' bast',\n",
       " ' basta',\n",
       " ' bat',\n",
       " ' batt',\n",
       " ' battl',\n",
       " ' be',\n",
       " ' be ',\n",
       " ' be a',\n",
       " ' be a ',\n",
       " ' be ab',\n",
       " ' be ad',\n",
       " ' be an',\n",
       " ' be b',\n",
       " ' be be',\n",
       " ' be bl',\n",
       " ' be c',\n",
       " ' be ca',\n",
       " ' be co',\n",
       " ' be d',\n",
       " ' be de',\n",
       " ' be di',\n",
       " ' be do',\n",
       " ' be e',\n",
       " ' be f',\n",
       " ' be fo',\n",
       " ' be g',\n",
       " ' be h',\n",
       " ' be i',\n",
       " ' be in',\n",
       " ' be l',\n",
       " ' be m',\n",
       " ' be ma',\n",
       " ' be me',\n",
       " ' be mo',\n",
       " ' be n',\n",
       " ' be no',\n",
       " ' be o',\n",
       " ' be on',\n",
       " ' be p',\n",
       " ' be pr',\n",
       " ' be r',\n",
       " ' be re',\n",
       " ' be s',\n",
       " ' be se',\n",
       " ' be so',\n",
       " ' be sp',\n",
       " ' be su',\n",
       " ' be t',\n",
       " ' be th',\n",
       " ' be to',\n",
       " ' be tr',\n",
       " ' be u',\n",
       " ' be un',\n",
       " ' be us',\n",
       " ' be v',\n",
       " ' be ve',\n",
       " ' be w',\n",
       " ' bea',\n",
       " ' beat',\n",
       " ' bec',\n",
       " ' beca',\n",
       " ' becam',\n",
       " ' becau',\n",
       " ' beco',\n",
       " ' becom',\n",
       " ' bee',\n",
       " ' been',\n",
       " ' been ',\n",
       " ' bef',\n",
       " ' befo',\n",
       " ' befor',\n",
       " ' beg',\n",
       " ' begi',\n",
       " ' begin',\n",
       " ' beh',\n",
       " ' beha',\n",
       " ' behav',\n",
       " ' behi',\n",
       " ' behin',\n",
       " ' bei',\n",
       " ' bein',\n",
       " ' being',\n",
       " ' bel',\n",
       " ' beli',\n",
       " ' belie',\n",
       " ' belo',\n",
       " ' belon',\n",
       " ' below',\n",
       " ' ben',\n",
       " ' bene',\n",
       " ' benef',\n",
       " ' ber',\n",
       " ' bes',\n",
       " ' best',\n",
       " ' best ',\n",
       " ' bet',\n",
       " ' bett',\n",
       " ' bette',\n",
       " ' betw',\n",
       " ' betwe',\n",
       " ' bey',\n",
       " ' beyo',\n",
       " ' beyon',\n",
       " ' bi',\n",
       " ' bia',\n",
       " ' bias',\n",
       " ' bias ',\n",
       " ' biase',\n",
       " ' bib',\n",
       " ' bibl',\n",
       " ' big',\n",
       " ' big ',\n",
       " ' bil',\n",
       " ' bill',\n",
       " ' bio',\n",
       " ' biog',\n",
       " ' biogr',\n",
       " ' bir',\n",
       " ' birt',\n",
       " ' birth',\n",
       " ' bit',\n",
       " ' bit ',\n",
       " ' bit o',\n",
       " ' bitc',\n",
       " ...]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect_char.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((159571, 20000), (159571, 40000))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_vect.shape, tr_vect_char.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sparse.hstack([train_vect, tr_vect_char])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = sparse.hstack([test_vect, ts_vect_char])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   toxic\n",
       "0      0\n",
       "1      0\n",
       "2      0\n",
       "3      0\n",
       "4      0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#target_col = ['toxic', 'severe_toxic', 'obscene', 'threat','insult', 'identity_hate']\n",
    "target_col = ['toxic']\n",
    "y = dftrain[target_col]\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153164\n",
      "1\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " ...\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "print(x_test.shape[0])\n",
    "print(y.shape[1])\n",
    "print(np.zeros((x_test.shape[0],y.shape[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prd = np.zeros((x_test.shape[0],y.shape[1]))\n",
    "cv_score =[]\n",
    "    #training \n",
    "lr = LogisticRegression(C=2,random_state = 42,class_weight = 'balanced')\n",
    "print('Column:{''}'.format(\"toxic\")) \n",
    "lr.fit(X,y[\"toxic\"])\n",
    "    \n",
    "# prédiction\n",
    "pred =  lr.predict(X)\n",
    "\n",
    "pred_pro = lr.predict_proba(X)[:,1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test =  lr.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prd = np.zeros((x_test.shape[0],y.shape[1]))\n",
    "cv_score =[]\n",
    "for i,col in enumerate(target_col):\n",
    "    #training \n",
    "    lr = LogisticRegression(C=2,random_state = 42,class_weight = 'balanced')\n",
    "    print('Column:{''}'.format(col)) \n",
    "    lr.fit(X,y[col])\n",
    "    \n",
    "    # prédiction\n",
    "    pred =  lr.predict(X)\n",
    "    print('\\nConfusion matrix\\n',confusion_matrix(y[col],pred))\n",
    "    print('\\nclassification_report\\n', classification_report(y[col],pred))\n",
    "    \n",
    "    # ROC\n",
    "    pred_pro = lr.predict_proba(X)[:,1]\n",
    "    frp,trp,thres = roc_curve(y[col],pred_pro)\n",
    "    auc_val =auc(frp,trp)\n",
    "    plt.figure(figsize=(5,3))\n",
    "    plt.plot([0,1],[0,1],color='b')\n",
    "    \n",
    "    plt.plot(frp,trp,color='r',label= 'AUC = %.2f'%auc_val)\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.xlabel('True positive rate')\n",
    "    plt.ylabel('False positive rate')\n",
    "    plt.title('ROC : {}'.format(col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#del train_vect, test_vect, tr_vect_char, ts_vect_char\n",
    "#gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in target_col:\n",
    "    print(100 * '=')\n",
    "    print(\"Column:\",col)\n",
    "    pred =  lr.predict(X)\n",
    "    print('\\nConfusion matrix\\n',confusion_matrix(y[col],pred))\n",
    "    print('\\nclassification_report\\n', classification_report(y[col],pred))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in target_col:    \n",
    "    pred_pro = lr.predict_proba(X)[:,1]\n",
    "    frp,trp,thres = roc_curve(y[col],pred_pro)\n",
    "    auc_val =auc(frp,trp)\n",
    "    plt.figure(figsize=(5,3))\n",
    "    plt.plot([0,1],[0,1],color='b')\n",
    "    \n",
    "    plt.plot(frp,trp,color='r',label= 'AUC = %.2f'%auc_val)\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.xlabel('True positive rate')\n",
    "    plt.ylabel('False positive rate')\n",
    "    plt.title('ROC : {}'.format(col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prd_1 = pd.DataFrame(prd,columns=y.columns)\n",
    "submit = pd.concat([dftest['id'],prd_1],axis=1)\n",
    "#submit.to_csv('toxic_lr.csv.gz',compression='gzip',index=False)\n",
    "#submit.to_csv('toxic_lr.csv',index=False)\n",
    "submit.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y, \n",
    "                                                    test_size = 0.3,\n",
    "                                                   stratify= y,\n",
    "                                                   random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "#from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "#from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 40\n",
    "classifiers = []\n",
    "#classifiers.append(SVC(random_state=random_state))\n",
    "#classifiers.append(DecisionTreeClassifier(random_state=random_state))\n",
    "#classifiers.append(KNeighborsClassifier())\n",
    "classifiers.append(LogisticRegression(random_state=random_state))\n",
    "classifiers.append(RandomForestClassifier(random_state=random_state))\n",
    "classifiers.append(MultinomialNB())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cv_results = []\n",
    "for classifier in classifiers:\n",
    "    cv_results.append(cross_val_score(classifier, \n",
    "                                     X_train,\n",
    "                                     np.ravel(y_train),\n",
    "                                     scoring='accuracy',\n",
    "                                     cv=3,\n",
    "                                     n_jobs=4))\n",
    "\n",
    "cv_means = []\n",
    "cv_std = []\n",
    "for cv_result in cv_results:\n",
    "    cv_means.append(cv_result.mean())\n",
    "    cv_std.append(cv_result.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_res = pd.DataFrame({\"CrossValMeans\":cv_means, \n",
    "                       \"CrossValErros\":cv_std,\n",
    "                      \"Algorithm\": [\n",
    "                                   \"Logistic Reg\",\n",
    "                                   \"Random Forest\",\n",
    "                                   \"Naive Bayes\"]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CrossValMeans</th>\n",
       "      <th>CrossValErros</th>\n",
       "      <th>Algorithm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.959525</td>\n",
       "      <td>0.000628</td>\n",
       "      <td>Logistic Reg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.949838</td>\n",
       "      <td>0.000521</td>\n",
       "      <td>Random Forest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.945371</td>\n",
       "      <td>0.000918</td>\n",
       "      <td>Naive Bayes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CrossValMeans  CrossValErros      Algorithm\n",
       "0       0.959525       0.000628   Logistic Reg\n",
       "1       0.949838       0.000521  Random Forest\n",
       "2       0.945371       0.000918    Naive Bayes"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Cross Val Scores')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "g = sns.barplot(\"CrossValMeans\", \"Algorithm\", data = cv_res)\n",
    "g.set_xlabel(\"Mean Accuracy\")\n",
    "g.set_title(\"Cross Val Scores\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CrossValMeans</th>\n",
       "      <th>CrossValErros</th>\n",
       "      <th>Algorithm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.945371</td>\n",
       "      <td>0.000918</td>\n",
       "      <td>Naive Bayes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.949838</td>\n",
       "      <td>0.000521</td>\n",
       "      <td>Random Forest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.959525</td>\n",
       "      <td>0.000628</td>\n",
       "      <td>Logistic Reg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CrossValMeans  CrossValErros      Algorithm\n",
       "2       0.945371       0.000918    Naive Bayes\n",
       "1       0.949838       0.000521  Random Forest\n",
       "0       0.959525       0.000628   Logistic Reg"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_res.sort_values(\"CrossValMeans\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "votingC = VotingClassifier(estimators=[\n",
    "    (\"LogReg\", classifiers[1]),\n",
    "    (\"Naive Bayes\", classifiers[2]),\n",
    "    (\"RF\", classifiers[0])\n",
    "], voting = \"hard\", n_jobs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "votingC.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(votingC,X_train, np.ravel(y_train), scoring=\"accuracy\", cv=10).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
